{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "!Certainly! Here's your markdown with the exact dataset description:\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŽ¶ Mission: DJ DataBeatz to the moon\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "youâ€™ve been hired. By DJ DataBeatz. You probably havenâ€™t heard of himâ€”yet. Heâ€™s the next big thing in music, just getting started, and totally under the radar. Your job? Help him become the best DJ ever. If you succeed, youâ€™re not just shaping the future of musicâ€”youâ€™re going on tour with him. And when DJ DataBeatz makes it big, youâ€™ll be right there with him, sharing the profits and living the lifestyle.\n",
    "\n",
    "No vinyl spinning, no flashy lightsâ€”just you, the data, and the beats. Popularity, Genres, Best date of release, Danceability, tempo, energyâ€”youâ€™ll be the unseen hand shaping DJ DataBeatz into something the worldâ€™s never seen before. The world wonâ€™t know what hit them. But you will. Youâ€™ll know exactly how DJ DataBeatz is going to take over the music scene, one beat at a time.\n",
    "\n",
    "![](media/dj_databeatz.jpeg)\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Š About the Dataset\n",
    "\n",
    "**Dataset Overview:**  \n",
    "This dataset provides a detailed analysis of various musical tracks, along with attributes that describe each trackâ€™s unique characteristics. Here's a breakdown of the variables:\n",
    "\n",
    "| **Variable**                | **Class**     | **Description**                                                                                                                                      |\n",
    "|-----------------------------|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| track_id                    | character     | Song unique ID                                                                                                                                      |\n",
    "| track_name                  | character     | Song Name                                                                                                                                          |\n",
    "| track_artist                | character     | Song Artist                                                                                                                                        |\n",
    "| track_popularity            | double        | Song Popularity (0-100) where higher is better                                                                                                      |\n",
    "| track_album_id              | character     | Album unique ID                                                                                                                                     |\n",
    "| track_album_name            | character     | Song album name                                                                                                                                     |\n",
    "| track_album_release_date    | character     | Date when album released                                                                                                                            |\n",
    "| playlist_name               | character     | Name of playlist                                                                                                                                     |\n",
    "| playlist_id                 | character     | Playlist ID                                                                                                                                         |\n",
    "| playlist_genre              | character     | Playlist genre                                                                                                                                      |\n",
    "| playlist_subgenre           | character     | Playlist subgenre                                                                                                                                   |\n",
    "| danceability                | double        | Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. |\n",
    "| energy                      | double        | Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. |\n",
    "| key                          | double        | The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = Câ™¯/Dâ™­, 2 = D, and so on. If no key was detected, the value is -1. |\n",
    "| loudness                    | double        | The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 dB. |\n",
    "| mode                         | double        | Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0. |\n",
    "| speechiness                 | double        | Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. |\n",
    "| acousticness                | double        | A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. |\n",
    "| instrumentalness            | double        | Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. |\n",
    "| liveness                    | double        | Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live. |\n",
    "| valence                     | double        | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). |\n",
    "| tempo                        | double        | The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. |\n",
    "| duration_ms                 | double        | Duration of song in milliseconds                                                                                                                    |\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“… Timeline of Tasks\n",
    "\n",
    "Hereâ€™s a timeline to guide you through the symphonic process of analyzing this dataset. Letâ€™s get started:\n",
    "\n",
    "1. **Load the dataset files into a Pandas DataFrame** (17:45 - 18:00)  \n",
    "   Unleash the power of pandas and get the data into a manageable form.\n",
    "   \n",
    "2. **Understand the data** - Explore each column, NaNs, identify patterns (18:00 - 18:15)  \n",
    "   Get familiar with the musical dimensions and clean up the dataset.\n",
    "\n",
    "3. **Calculate univariate statistics and create graphs** - Dive into single-variable analysis (18:15 - 18:40)  \n",
    "   Create insightful visualizations that uncover hidden trends.\n",
    "\n",
    "4. **Create multivariate statistics and graphs** - Explore how multiple features interact (18:40 - 19:20)  \n",
    "   Show off the relationships between tempo, energy, danceability, and more.\n",
    "\n",
    "5. **Prepare notebook for presentation** - Polish your findings and clean up the code (19:20 - 19:30)  \n",
    "   Get everything ready for the grand performance.\n",
    "\n",
    "6. **Organize presentation** - Structure how youâ€™ll share your insights (19:30 - 19:40)  \n",
    "   Make sure the audience is dancing to your data analysis!\n",
    "\n",
    "7. **Presentation start** - Take the stage and present your findings! (19:45)  \n",
    "   Show everyone how this data sings!\n",
    "\n",
    "---\n",
    "\n",
    "Time to put your music knowledge to work, and turn this data into a chart-topping performance! ðŸŽ¤ðŸŽ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
