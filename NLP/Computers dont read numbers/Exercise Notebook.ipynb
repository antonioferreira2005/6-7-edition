{"cells":[{"cell_type":"markdown","metadata":{},"source":["# String Manipulation and Regex in Python\n","\n","In Python, a **string** is a sequence of characters enclosed within either single quotes (' ') or double quotes (\" \"). Strings are a fundamental data type used to represent text data. They are versatile and offer various methods for manipulation.\n","\n","**Counting Occurrences**:  \n","You can count the number of occurrences of a specific character or substring within a string using the `count` method.\n","\n","**Sub-String Slicing**:  \n","To extract a sub-string from a string, you can use slicing. Slicing is done using square brackets.\n","\n","**Joining Strings**:  \n","To join a list of string objects into a single string with a specified separator, you can use the `join` method.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re"]},{"cell_type":"markdown","metadata":{},"source":["## Exercises\n","\n","Below are exercises to practice string manipulation, regex, and tokenization. Complete the tasks using the provided functions."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 1: Join List into String\n","words = [\"Hello\", \"world\", \"Python\"]\n","# Use join method to create a sentence\n","sentence =  # Your code here\n","print(sentence)  # Expected output: 'Hello world Python'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 2: Count Occurrences\n","y = \"Never gonna let you down\"\n","# Count the number of occurrences of 'a'\n","count_a =  # Your code here\n","print(count_a)  # Expected output: 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 3: Regex Substitution\n","x1 = \"The pin code is 1234\"\n","# Substitute the digits with 'X'\n","modified_x1 = re.sub( # Your regex pattern here, x1)\n","print(modified_x1)  # Expected output: 'The pin code is XXXX'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 4: Regex Clean-up\n","x2 = \"This@is~a#messy_%%%%%%%%%%%%%%%%%%%%%%%%%%%%string\"\n","# Clean special characters and remove excess spaces\n","cleaned_x2 = re.sub( # Your regex pattern here, x2)\n","print(cleaned_x2)  # Expected output: 'This is a messy string'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 5: Extracting Numbers\n","def extract_numbers(text):\n","    # Define a regex pattern to match numbers (integers and floating point)\n","    pattern = ' # Your regex pattern here\n","    # Use findall to extract numbers\n","    numbers = re.findall(pattern, text)\n","    return numbers\n","# Test the function\n","sample_text = 'Call me at 123-456-7890 or visit me at 134.56.789'\n","result = extract_numbers(sample_text)\n","print(result)  # Expected output: ['123', '456', '7890', '134', '56', '789']"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenization\n","Tokenization is the process of breaking down a text into smaller units like words or phrases. Below are some exercises on tokenization."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","from nltk.tokenize import RegexpTokenizer\n","\n","text = \"John's dog, Max, loves chasing after tennis balls in the park. It's his favorite activity!\"\n","# Create a tokenizer\n","tokenizer = RegexpTokenizer('\\w+')\n","# Tokenize the text\n","tokens = tokenizer.tokenize(text)\n","print(tokens)  # Expected output: list of tokens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise 6: Custom Tokenizer\n","text = \"Hello there! How are you today?\"\n","# Implement another method of tokenization\n","# Example: WhitespaceTokenizer\n","whitespace_tokens =  # Your code here\n","print(whitespace_tokens)  # Expected output: list of tokens based on whitespace"]},{"cell_type":"markdown","metadata":{},"source":["# Sklearn CountVectorizer\n","Finally, let's use sklearn's CountVectorizer to create a bag of words representation for a sample text."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","corpus = [\n","    \"I wanted the pineapple from the competition.\",\n","    \"This pineapple was the ultimate prize.\",\n","    \"And the third team stole my pineapple dream.\",\n","    \"Did you see the first pineapple at the competition?\"\n","]\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# try get_feature_names_out method to see the columns\n","\n","\n","#try toarray method to see the representantion of the words"]},{"cell_type":"markdown","metadata":{},"source":["These exercises should help improve your skills in string manipulation, regex, and tokenization using Python!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}
