{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsung-ai-course/6-7-edition/blob/main/Supervised%20Learning/SVM_Hyperparameter_Tuning_WineQuality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd13d97a",
      "metadata": {
        "id": "dd13d97a"
      },
      "source": [
        "# Hyperparameter Tuning Practice: Wine Quality Dataset (SVM)\n",
        "In this notebook, you'll explore hyperparameter tuning using Support Vector Machines (SVM) on the Wine Quality dataset. You'll learn how to tune key hyperparameters, visualize results, and interpret the impact of these hyperparameters.\n",
        "\n",
        "## Objectives:\n",
        "1. Load and preprocess the Wine Quality dataset.\n",
        "2. Split the data into training and test sets.\n",
        "3. Perform hyperparameter tuning for SVM.\n",
        "4. Visualize training vs validation performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64c51d5",
      "metadata": {
        "id": "e64c51d5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Enable inline plots\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec4cbd4",
      "metadata": {
        "id": "9ec4cbd4"
      },
      "source": [
        "## Step 1: Load the Wine Quality Dataset\n",
        "We'll use the Wine Quality dataset, which contains information about different wines and their quality ratings. You can download it from: [Wine Quality Dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset) and find more information, or load it directly from github.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9fd2bf",
      "metadata": {
        "id": "ae9fd2bf"
      },
      "outputs": [],
      "source": [
        "# Load the dataset (you'll need to download 'winequality-red.csv')\n",
        "url = 'https://raw.githubusercontent.com/samsung-ai-course/6-7-edition/refs/heads/main/Supervised%20Learning/Datasets/WineQT.csv'\n",
        "data = #TODO:\n",
        "\n",
        "# Display the first few rows\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1.1: Free EDA\n",
        "Here you are free to explore the data in whatever it be of use to you.\n",
        "* .describe()\n",
        "* .info()\n",
        "* plot correlation matrixes\n",
        "* up to you\n"
      ],
      "metadata": {
        "id": "vsW58tmTxXpK"
      },
      "id": "vsW58tmTxXpK"
    },
    {
      "cell_type": "code",
      "source": [
        "#up to you\n",
        "#whatever you do what conclusion can you take from it? If any."
      ],
      "metadata": {
        "id": "ZNBY7p0rx5Ya"
      },
      "id": "ZNBY7p0rx5Ya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d9f2a692",
      "metadata": {
        "id": "d9f2a692"
      },
      "source": [
        "## Step 2: Data Preprocessing\n",
        "- Separate features and target variable.\n",
        "- Split the dataset into training and testing sets.\n",
        "- Optionally perform some feature engineering and assess its impact."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = #TODO p.s check .drop\n",
        "y = #TODO"
      ],
      "metadata": {
        "id": "oLYZSR8qvvWd"
      },
      "id": "oLYZSR8qvvWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06edeac6",
      "metadata": {
        "id": "06edeac6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Bin target variable into 'low', 'medium', and 'high' quality for classification -> https://en.wikipedia.org/wiki/Data_binning\n",
        "y = #TODO lets turn this into a simpler classification problem p.s lookup pd.cut\n",
        "#p.s this will be a multi-class problem instead of a simple binary one. Class imbalance might cause more problems here..? More on that on the next class, but think about it.\n",
        "#After you finish this notebook, do not perform binning.\n",
        "\n",
        "# Split into training and testing sets\n",
        "#TODO\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4366d3ee",
      "metadata": {
        "id": "4366d3ee"
      },
      "source": [
        "## Step 3: SVM Hyperparameter Tuning\n",
        "Experiment with different values for `C` (regularization parameter) and kernel types to see how they affect training and validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77faf2b8",
      "metadata": {
        "id": "77faf2b8"
      },
      "outputs": [],
      "source": [
        "# Define parameter grid for SVM\n",
        "# Note: the more cross validations (cv) and the bigger the search space, the slower this can be\n",
        "param_grid = {\n",
        "    'C': [0.1],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['auto']  # Only relevant for non-linear kernels like 'rbf'\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "svm = SVC()\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and scores\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_search = #TODO -> https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "#TODO\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)"
      ],
      "metadata": {
        "id": "VqPllk7GwYRQ"
      },
      "id": "VqPllk7GwYRQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5b00c2eb",
      "metadata": {
        "id": "5b00c2eb"
      },
      "source": [
        "## Step 4: Visualize the Results\n",
        "Plot the cross-validation accuracy for different values of `C` to understand its impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df511406",
      "metadata": {
        "id": "df511406"
      },
      "outputs": [],
      "source": [
        "# Extract results from grid search\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# Filter for linear and rbf kernels separately\n",
        "linear_results = results[results['param_kernel'] == 'linear']\n",
        "rbf_results = results[results['param_kernel'] == 'rbf']\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(linear_results['param_C'], linear_results['mean_test_score'], label='Linear Kernel', marker='o')\n",
        "plt.plot(rbf_results['param_C'], rbf_results['mean_test_score'], label='RBF Kernel', marker='o')\n",
        "plt.xscale('log')\n",
        "plt.title('SVM: Effect of C on Accuracy')\n",
        "plt.xlabel('C (Regularization Parameter)')\n",
        "plt.ylabel('Cross-Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation\n",
        "\n",
        "Understand precision and recall, plot confusion matrix and evaluate the model more in detail.\n",
        "\n",
        "Note that after the hyperparameters are found we typically train the model again on all *train* dataset."
      ],
      "metadata": {
        "id": "pqgfJEjIyWvg"
      },
      "id": "pqgfJEjIyWvg"
    },
    {
      "cell_type": "code",
      "source": [
        "#;)"
      ],
      "metadata": {
        "id": "hRbPXCJqymEx"
      },
      "id": "hRbPXCJqymEx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
